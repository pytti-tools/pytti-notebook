{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "pytti 5 beta.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WksDx4_To_su"
      },
      "source": [
        "#pytti: python text to image\n",
        "\n",
        "---\n",
        "This is a closed beta. Leak it if you must, information wants to be free.\n",
        "\n",
        "[pytti is made possible by supporters like you.](https://www.patreon.com/sportsracer48) [Thank you.](https://www.youtube.com/watch?v=TexDW6nEhgU)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0hRb20yxxsc",
        "cellView": "form"
      },
      "source": [
        "# @title Licensed under the MIT License\n",
        "# Copyleft (c) 2021 Henry Rachootin\n",
        "\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "# of this software and associated documentation files (the \"Software\"), to deal\n",
        "# in the Software without restriction, including without limitation the rights\n",
        "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "# copies of the Software, and to permit persons to whom the Software is\n",
        "# furnished to do so, subject to the following conditions:\n",
        "\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
        "# THE SOFTWARE."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LjPC_0vN87t"
      },
      "source": [
        "# Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW4VrGKU0VUp"
      },
      "source": [
        "`scenes:` Descriptions of scenes you want generated, separated by `||`. Each scene can contain multiple prompts, separated by `|`.\n",
        "\n",
        "*Example:* `Winter sunrise | icy landscape || Winter day | snowy skyline || Winter sunset | chilly air || Winter night | clear sky` would go through several winter scenes.\n",
        "\n",
        "**Advanced:** weight prompts with `description:weight`. Higher `weight` values will be prioritized by the optimizer, and negative `weight` values will remove the description from the image. The default weight is $1$. Weights can also be functions of $t$ to change over the course of an animation.\n",
        "\n",
        "*Example scene:* `blue sky:10|martian landscape|red sky:-1` would try to turn the martian sky blue.\n",
        "\n",
        "**Advanced:** stop prompts once the image matches them sufficiently with `description:weight:stop`. `stop` should be between $0$ and $1$ for positive prompts, or between $-1$ and $0$ for negative prompts. Lower `stop` values will have more effect on the image (remember that $-1<-0.5<0$). A prompt with a negative `weight` will often go haywire without a stop. Stops can also be functions of $t$ to change over the course of an animation.\n",
        "\n",
        "*Example scene:* `Feathered dinosaurs|birds:1:0.87|scales:-1:-.9|text:-1:-.9` Would try to make feathered dinosaurs, lightly like birds, without scales or text, but without making 'anti-scales' or 'anti-text.'\n",
        "\n",
        "#**NEW:**\n",
        "\n",
        "**Advanced:** Use `description:weight_mask description` with a text prompt as `mask`. The prompt will only be applied to areas of the image that match `mask description` according to CLIP.\n",
        "\n",
        "*Example scene:* `Khaleesi Daenerys Targaryen | mother of dragons | dragon:3_baby` would only apply the weight `dragon` to parts of the image that match `baby`, thus turning the babies that `mother` tends to make into dragons (hopefully).\n",
        "\n",
        "**Advanced:** Use `description:weight_[mask]` with a URL or path to an image, or a path to a .mp4 video to use as a `mask`. The prompt will only be applied to the masked (white) areas of the mask image. Use `description:weight_[-mask]` to apply the prompt to the black areas instead.\n",
        "\n",
        "*Example scene:* `sunlight:3_[mask.mp4]|midnight:3_[-mask.mp4]` Would apply `sunlight` in the white areas of `mask.mp4`, and `midnight` in the black areas.\n",
        "\n",
        "**Legacy:** Directional weights will still work as before, but they aren't as good as masks.\n",
        "\n",
        "**Advanced:** Use `[path or url]` as a prompt to add a semantic image prompt. This will be read by CLIP and understood as a near perfect text description of the image.\n",
        "\n",
        "*Example scene:* `[artist signature.png]:-1:-.95|[https://i.redd.it/ewpeykozy7e71.png]:3|fractal clouds|hole in the sky`\n",
        "\n",
        "---\n",
        "\n",
        "`scene_prefix:` text prepended to the beginning of each scene.\n",
        "\n",
        "*Example:* `Trending on Arstation|`\n",
        "\n",
        "`scene_suffix:` text appended to the end of each scene.\n",
        "\n",
        "*Example:* ` by James Gurney`\n",
        "\n",
        "`interpolation_steps:` number of steps to spend smoothly transitioning from the last scene at the start of each scene. $200$ is a good default. Set to $0$ to disable.\n",
        "\n",
        "`steps_per_scene:` total number of steps to spend rendering each scene. Should be at least `interpolation_steps`. This will indirectly control the total length of an animation.\n",
        "\n",
        "---\n",
        "#**NEW**: \n",
        "`direct_image_prompts:` paths or urls of images that you want your image to look like in a literal sense, along with `weight_mask` and `stop` values, separated by `|`.\n",
        "\n",
        "Apply masks to direct image prompts with `path or url of image:weight_path or url of mask` For video masks it must be a path to an mp4 file.\n",
        "\n",
        "**Legacy** latent image prompts are no more. They are now rolled into direct image prompts.\n",
        "\n",
        "---\n",
        "\n",
        "`init_image:` path or url of start image. Works well for creating a central focus.\n",
        "\n",
        "\n",
        "`direct_init_weight:` Defaults to $0$. Use the initial image as a direct image prompt. Equivalent to adding `init_image:direct_init_weight` as a `direct_image_prompt`. Supports weights, masks, and stops.\n",
        "\n",
        "`semantic_init_weight:` Defaults to $0$. Defaults to $0$. Use the initial image as a semantic image prompt. Equivalent to adding `[init_image]:direct_init_weight` as a prompt to each scene in `scenes`. Supports weights, masks, and stops. **IMPORTANT** since this is a semantic prompt, you still need to put the mask in `[` `]` to denote it as a path or url, otherwise it will be read as text instead of a file.\n",
        "\n",
        "---\n",
        "\n",
        "`width`, `height:` image size. Set one of these $-1$ to derive it from the aspect ratio of the init image.\n",
        "\n",
        "`pixel_size:` integer image scale factor. Makes the image bigger. Set to $1$ for VQGAN or face VRAM issues.\n",
        "\n",
        "`smoothing_weight:` makes the image smoother. Defaults to $0$ (no smoothing). Can also be negative for that deep fried look.\n",
        "\n",
        "`image_model:` select how your image will be represented.\n",
        "\n",
        "`vqgan_model:` select your VQGAN version (only for `image_model: VQGAN`)\n",
        "\n",
        "`random_initial_palette:` if checked, palettes will start out with random colors. Otherwise they will start out as grayscale. (only for `image_model: Limited Palette`)\n",
        "\n",
        "`palette_size:` number of colors in each palette. (only for `image_model: Limited Palette`)\n",
        "\n",
        "`palettes:` total number of palettes. The image will have `palette_size*palettes` colors total. (only for `image_model: Limited Palette`)\n",
        "\n",
        "`gamma:` relative gamma value. Higher values make the image darker and higher contrast, lower values make the image lighter and lower contrast. (only for `image_model: Limited Palette`). $1$ is a good default.\n",
        "\n",
        "`hdr_weight:` how strongly the optimizer will maintain the `gamma`. Set to $0$ to disable. (only for `image_model: Limited Palette`)\n",
        "\n",
        "`palette_normalization_weight:` how strongly the optimizer will maintain the palettes' presence in the image. Prevents the image from losing palettes. (only for `image_model: Limited Palette`)\n",
        "\n",
        "`show_palette:` check this box to see the palette each time the image is displayed. (only for `image_model: Limited Palette`)\n",
        "\n",
        "`target_pallete:` path or url of an image which the model will use to make the palette it uses.\n",
        "\n",
        "`lock_pallete:` force the model to use the initial palette (most useful from restore, but will force a grayscale image or a wonky palette otherwise).\n",
        "\n",
        "---\n",
        "\n",
        "`animation_mode:` select animation mode or disable animation.\n",
        "\n",
        "`sampling_mode:` how pixels are sampled during animation. `nearest` will keep the image sharp, but may look bad. `bilinear` will smooth the image out, and `bicubic` is untested :)\n",
        "\n",
        "`infill_mode:` select how new pixels should be filled if they come in from the edge.\n",
        "* mirror: reflect image over boundary\n",
        "* wrap: pull pixels from opposite side\n",
        "* black: fill with black \n",
        "* smear: sample closest pixel in image\n",
        "\n",
        "`pre_animation_steps:` number of steps to run before animation starts, to begin with a stable image. $250$ is a good default.\n",
        "\n",
        "`steps_per_frame:` number of steps between each image move. $50$ is a good default.\n",
        "\n",
        "`frames_per_second:` number of frames to render each second. Controls how $t$ is scaled.\n",
        "\n",
        "`direct_stabilization_weight: ` keeps the current frame as a direct image prompt. For `Video Source` this will use the current frame of the video as a direct image prompt. For `2D` and `3D` this will use the shifted version of the previous frame. Also supports masks: `weight_mask.mp4`.\n",
        "\n",
        "`semantic_stabilization_weight: ` keeps the current frame as a semantic image prompt. For `Video Source` this will use the current frame of the video as a direct image prompt. For `2D` and `3D` this will use the shifted version of the previous frame. Also supports masks: `weight_[mask.mp4]` or `weight_mask phrase`.\n",
        "\n",
        "`depth_stabilization_weight: ` keeps the depth model output somewhat consistent at a *VERY* steep performance cost. For `Video Source` this will use the current frame of the video as a semantic image prompt. For `2D` and `3D` this will use the shifted version of the previous frame. Also supports masks: `weight_mask.mp4`.\n",
        "\n",
        "`edge_stabilization_weight: ` keeps the images contours somewhat consistent at very little performance cost. For `Video Source` this will use the current frame of the video as a direct image prompt with a sobel filter. For `2D` and `3D` this will use the shifted version of the previous frame. Also supports masks: `weight_mask.mp4`.\n",
        "\n",
        "`flow_stabilization_weight: ` used for `animation_mode: 3D` and `Video Source` to prevent flickering. Comes with a slight performance cost for `Video Source`, and a great one for `3D`, due to implementation differences. Also supports masks: `weight_mask.mp4`. For video source, the mask should select the part of the frame you want to move, and the rest will be treated as a still background.\n",
        "\n",
        "---\n",
        "`video_path: ` path to mp4 file for `Video Source`\n",
        "\n",
        "`frame_stride` advance this many frames in the video for each output frame. This is surprisingly useful. Set to $1$ to render each frame. Video masks will also step at this rate.\n",
        "\n",
        "`reencode_each_frame: ` check this box to use each video frame as an `init_image` instead of warping each output frame into the init for the next. Cuts will still be detected and trigger a reencode.\n",
        "\n",
        "\n",
        "`flow_long_term_samples: ` Sample multiple frames into the past for consistent interpolation even with disocclusion, as described by [Manuel Ruder, Alexey Dosovitskiy, and Thomas Brox (2016)](https://arxiv.org/abs/1604.08610). Each sample is twice as far back in the past as the last, so the earliest sampled frame is $2^{\\text{long_term_flow_samples}}$ frames in the past. Set to $0$ to disable.\n",
        "\n",
        "---\n",
        "\n",
        "`translate_x:` horizontal image motion as a function of time $t$ in seconds.\n",
        "\n",
        "`translate_y:` vertical image motion as a function of time $t$ in seconds.\n",
        "\n",
        "`translate_z_3d:` forward image motion as a function of time $t$ in seconds. (only for `animation_mode:3D`)\n",
        "\n",
        "`rotate_3d:` image rotation as a quaternion $\\left[r,x,y,z\\right]$ as a function of time $t$ in seconds. (only for `animation_mode:3D`)\n",
        "\n",
        "`rotate_2d:` image rotation in degrees as a function of time $t$ in seconds. (only for `animation_mode:2D`)\n",
        "\n",
        "`zoom_x_2d:` horizontal image zoom as a function of time $t$ in seconds. (only for `animation_mode:2D`)\n",
        "\n",
        "`zoom_y_2d:` vertical image zoom as a function of time $t$ in seconds. (only for `animation_mode:2D`)\n",
        "\n",
        "`lock_camera:` check this box to prevent all scrolling or drifting. Makes for more stable 3D rotations. (only for `animation_mode:3D`)\n",
        "\n",
        "`field_of_view:` vertical field of view in degrees. (only for `animation_mode:3D`)\n",
        "\n",
        "`near_plane:` closest depth distance in pixels. (only for `animation_mode:3D`)\n",
        "\n",
        "`far_plane:` farthest depth distance in pixels. (only for `animation_mode:3D`)\n",
        "\n",
        "---\n",
        "\n",
        "`file_namespace:` output directory name.\n",
        "\n",
        "`allow_overwrite:` check to overwrite existing files in `file_namespace`.\n",
        "\n",
        "`display_every:` how many steps between each time the image is displayed in the notebook.\n",
        "\n",
        "`clear_every:` how many steps between each time notebook console is cleared.\n",
        "\n",
        "`display_scale:` image display scale in notebook. $1$ will show the image at full size. Does not affect saved images.\n",
        "\n",
        "`save_every:` how many steps between each time the image is saved. Set to `steps_per_frame` for consistent animation.\n",
        "\n",
        "`backups:` number of backups to keep (only the oldest backups are deleted). Large images make very large backups, so be warned. Set to `all` to save all backups. These are used for the `flow_long_term_samples` so be sure that this is at least $2^{\\text{flow_long_term_samples}}+1$ for `Video Source` mode.\n",
        "\n",
        "`show_graphs:` check this to see graphs of the loss values each time the image is displayed. Disable this for local runtimes.\n",
        "\n",
        "`approximate_vram_usage:` currently broken. Don't believe its lies.\n",
        "\n",
        "---\n",
        "\n",
        "`ViTB32, ViTB16, RN50, RN50x4:` select your CLIP models. These take a lot of VRAM.\n",
        "\n",
        "`learning_rate:` how quickly the image changes.\n",
        "\n",
        "`reset_lr_each_frame:` the optimizer will adaptively change the learning rate, so this will thwart it.\n",
        "\n",
        "`seed:` pseudorandom seed.\n",
        "\n",
        "---\n",
        "\n",
        "`cutouts:` number of cutouts. Reduce this to use less VRAM at the cost of quality and speed.\n",
        "\n",
        "`cut_pow:` should be positive. Large values shrink cutouts, making the image more detailed, small values expand the cutouts, making it more coherent. $1$ is a good default. $3$ or higher can cause crashes.\n",
        "\n",
        "`cutout_border:` should be between $0$ and $1$. Allows cutouts to poke out over the edges of the image by this fraction of the image size, allowing better detail around the edges of the image. Set to $0$ to disable. $0.25$ is a good default.\n",
        "\n",
        "`border_mode:` how to fill cutouts that stick out over the edge of the image. Match with `infill_mode` for consistent infill.\n",
        "\n",
        "* clamp: move cutouts back onto image\n",
        "* mirror: reflect image over boundary\n",
        "* wrap: pull pixels from opposite side\n",
        "* black: fill with black \n",
        "* smear: sample closest pixel in image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZt160ePEc8f"
      },
      "source": [
        "#Step 1: Setup\n",
        "Run the cells in this section once for each runtime, or after a factory reset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9C9tARLzyzq"
      },
      "source": [
        "#@title 1.1 Mount google drive (optional)\n",
        "#@markdown Mounting your drive is optional but recommended. You can even restore from google randomly\n",
        "#@markdown kicking you out if you mount your drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "!mkdir -p /content/drive/MyDrive/pytti_test\n",
        "%cd /content/drive/MyDrive/pytti_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RosI5DYxtjh0",
        "cellView": "form"
      },
      "source": [
        "#@title 1.2 NVIDIA-SMI (optional)\n",
        "#@markdown View information about your runtime GPU.\n",
        "#@markdown Google will connect you to an industrial strength GPU, which is needed to run\n",
        "#@markdown this notebook. You can also disable error checking on your GPU to get some\n",
        "#@markdown more VRAM, at a marginal cost to stability. You will have to restart the runtime after\n",
        "#@markdown disabling it.\n",
        "enable_error_checking = False#@param {type:\"boolean\"}\n",
        "if enable_error_checking:\n",
        "  !nvidia-smi\n",
        "else:\n",
        "  !nvidia-smi\n",
        "  !nvidia-smi -i 0 -e 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAGyDOe2o9AE",
        "cellView": "form"
      },
      "source": [
        "#@title 1.3 Install everything else\n",
        "#@markdown Run this cell on a fresh runtime to install the libraries and modules.\n",
        "from os.path import exists as path_exists\n",
        "if path_exists('/content/drive/MyDrive/pytti_test'):\n",
        "  %cd /content/drive/MyDrive/pytti_test\n",
        "\n",
        "try:\n",
        "  from adjustText import adjust_text\n",
        "  import pytti, torch\n",
        "  everything_installed = True\n",
        "except ModuleNotFoundError:\n",
        "  everything_installed = False\n",
        "def install_everything():\n",
        "  !pip install tensorflow==1.15.2\n",
        "  !pip install transformers                                        &> /dev/null                              \n",
        "  !pip install PyGLM                                               &> /dev/null\n",
        "  !pip install ftfy regex tqdm omegaconf pytorch-lightning         &> /dev/null\n",
        "  !pip install kornia                                              &> /dev/null\n",
        "  !pip install einops                                              &> /dev/null\n",
        "  !pip install imageio-ffmpeg                                      &> /dev/null\n",
        "  !pip install adjustText exrex bunch                              &> /dev/null\n",
        "  !pip install matplotlib-label-lines                              &> /dev/null\n",
        "  !git clone https://github.com/openai/CLIP.git                    &> /dev/null\n",
        "  !git clone https://github.com/CompVis/taming-transformers.git    &> /dev/null\n",
        "  if not path_exists('./pytti'):\n",
        "    !git clone --branch p5 https://github.com/sportsracer48/pytti.git        &> /dev/null\n",
        "  else:\n",
        "    !rm -r pytti\n",
        "    !git clone --branch p5 https://github.com/sportsracer48/pytti.git\n",
        "  !git clone https://github.com/shariqfarooq123/AdaBins.git        &> /dev/null\n",
        "  !git clone https://github.com/zacjiang/GMA.git                   &> /dev/null\n",
        "  !mkdir -p AdaBins/pretrained\n",
        "  if not path_exists('AdaBins/pretrained/AdaBins_nyu.pt'):\n",
        "   !gdown https://drive.google.com/uc?id=1lvyZZbC9NLcS8a__YPcUP7rDiIpbRpoF\n",
        "   if not path_exists('AdaBins_nyu.pt'):\n",
        "     !gdown https://drive.google.com/uc?id=1zgGJrkFkJbRouqMaWArXE4WF_rhj-pxW\n",
        "   !mv AdaBins_nyu.pt AdaBins/pretrained/AdaBins_nyu.pt\n",
        "  \n",
        "  from pytti.Notebook import change_tqdm_color\n",
        "  change_tqdm_color()\n",
        "  !mkdir -p images_out\n",
        "  !mkdir -p videos\n",
        "\n",
        "force_install = True #@param{type:\"boolean\"}\n",
        "if not everything_installed or force_install:\n",
        "  install_everything()\n",
        "elif everything_installed:\n",
        "  from pytti.Notebook import change_tqdm_color\n",
        "  change_tqdm_color()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcayyBJjE-qy"
      },
      "source": [
        "# Step 2: Run it!\n",
        "Edit the parameters, or load saved parameters, then run the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiKD7os1pyXW",
        "cellView": "form"
      },
      "source": [
        "#@title #2.1 Parameters:\n",
        "#@markdown ---\n",
        "from os.path import exists as path_exists\n",
        "if path_exists('/content/drive/MyDrive/pytti_test'):\n",
        "  %cd /content/drive/MyDrive/pytti_test\n",
        "  drive_mounted = True\n",
        "else:\n",
        "  drive_mounted = False\n",
        "try:\n",
        "  from pytti.Notebook import change_tqdm_color, get_last_file\n",
        "except ModuleNotFoundError:\n",
        "  if drive_mounted:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('ERROR: please run setup (step 1.3).')\n",
        "  else:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('WARNING: drive is not mounted.\\nERROR: please run setup (step 1.3).')\n",
        "change_tqdm_color()\n",
        "\n",
        "import glob, json, random, re, math\n",
        "try:\n",
        "  from bunch import Bunch\n",
        "except ModuleNotFoundError:\n",
        "  if drive_mounted:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('ERROR: please run setup (step 1.3).')\n",
        "  else:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('WARNING: drive is not mounted.\\nERROR: please run setup (step 1.3).')\n",
        "\n",
        "#these are used to make the defaults look pretty\n",
        "model_default = None\n",
        "random_seed = None\n",
        "all  = math.inf\n",
        "derive_from_init_aspect_ratio = -1\n",
        "\n",
        "def define_parameters():\n",
        "  locals_before = locals().copy()\n",
        "  #@markdown ###Prompts:\n",
        "  \n",
        "  scenes = \"deep space habitation ring made of glass | galactic nebula | wow! space is full of fractal creatures darting around everywhere like fireflies\"#@param{type:\"string\"}\n",
        "  scene_prefix = \"astrophotography #pixelart | image credit nasa | space full of cybernetic neon:3_galactic nebula | isometric pixelart by Sachin Teng | \"#@param{type:\"string\"}\n",
        "  scene_suffix = \"| satellite image:-1:-.95 | text:-1:-.95 | anime:-1:-.95 | watermark:-1:-.95 | backyard telescope:-1:-.95 | map:-1:-.95\"#@param{type:\"string\"}\n",
        "  interpolation_steps = 0#@param{type:\"number\"}\n",
        "  steps_per_scene =  60100#@param{type:\"raw\"}\n",
        "  #@markdown ---\n",
        "  #@markdown ###Image Prompts:\n",
        "  direct_image_prompts   = \"\"#@param{type:\"string\"}\n",
        "  #@markdown ---\n",
        "  #@markdown ###Initial image:\n",
        "  init_image = \"\"#@param{type:\"string\"}\n",
        "  direct_init_weight =  \"\"#@param{type:\"string\"}\n",
        "  semantic_init_weight = \"\"#@param{type:\"string\"}\n",
        "  #@markdown ---\n",
        "  #@markdown ###Image:\n",
        "  #@markdown Use `image_model` to select how the model will encode the image\n",
        "  image_model = \"Limited Palette\" #@param [\"VQGAN\", \"Limited Palette\", \"Unlimited Palette\"]\n",
        "\n",
        "  #@markdown image_model | description | strengths | weaknesses\n",
        "  #@markdown --- | -- | -- | --\n",
        "  #@markdown  VQGAN | classic VQGAN image | smooth images | limited datasets, slow, VRAM intesnsive \n",
        "  #@markdown  Limited Palette | pytti differentiable palette | fast,  VRAM scales with `palettes` | pixel images\n",
        "  #@markdown  Unlimited Palette | simple RGB optimization | fast, VRAM efficient | pixel images\n",
        "  \n",
        "  #@markdown The output image resolution will be `width` $\\times$ `pixel_size` by height $\\times$ `pixel_size` pixels.\n",
        "  #@markdown The easiest way to run out of VRAM is to select `image_model` VQGAN without reducing\n",
        "  #@markdown `pixel_size` to $1$.\n",
        "\n",
        "  #@markdown For `animation_mode: 3D` the minimum resoultion is about 450 by 400 pixels.\n",
        "  width =  180#@param {type:\"raw\"}\n",
        "  height =  112#@param {type:\"raw\"}\n",
        "  pixel_size = 4#@param{type:\"number\"}\n",
        "  smoothing_weight =  0.02#@param{type:\"number\"}\n",
        "  #@markdown `VQGAN` specific settings:\n",
        "  vqgan_model = \"sflckr\" #@param [\"imagenet\", \"coco\", \"wikiart\", \"sflckr\", \"openimages\"]\n",
        "  #@markdown `Limited Palette` specific settings:\n",
        "  random_initial_palette = False#@param{type:\"boolean\"}\n",
        "  palette_size = 6#@param{type:\"number\"}\n",
        "  palettes   = 9#@param{type:\"number\"}\n",
        "  gamma = 1#@param{type:\"number\"}\n",
        "  hdr_weight = 0.01#@param{type:\"number\"}\n",
        "  palette_normalization_weight = 0.2#@param{type:\"number\"}\n",
        "  show_palette = False #@param{type:\"boolean\"}\n",
        "  target_palette = \"\"#@param{type:\"string\"}\n",
        "  lock_palette = False #@param{type:\"boolean\"}\n",
        "  #@markdown ---\n",
        "  #@markdown ###Animation:\n",
        "  animation_mode = \"3D\" #@param [\"off\",\"2D\", \"3D\", \"Video Source\"]\n",
        "  sampling_mode = \"bicubic\" #@param [\"bilinear\",\"nearest\",\"bicubic\"]\n",
        "  infill_mode = \"wrap\" #@param [\"mirror\",\"wrap\",\"black\",\"smear\"]\n",
        "  pre_animation_steps =  100#@param{type:\"number\"}\n",
        "  steps_per_frame =  50#@param{type:\"number\"}\n",
        "  frames_per_second =  12#@param{type:\"number\"}\n",
        "  #@markdown ---\n",
        "  #@markdown ###Stabilization Weights:\n",
        "  direct_stabilization_weight = \"\"#@param{type:\"string\"}\n",
        "  semantic_stabilization_weight = \"\"#@param{type:\"string\"}\n",
        "  depth_stabilization_weight = \"\"#@param{type:\"string\"}\n",
        "  edge_stabilization_weight = \"\"#@param{type:\"string\"}\n",
        "  #@markdown `flow_stabilization_weight` is used for `animation_mode: 3D` and `Video Source`\n",
        "  flow_stabilization_weight = \"\"#@param{type:\"string\"}\n",
        "  #@markdown ---\n",
        "  #@markdown ###Video Tracking:\n",
        "  #@markdown Only for `animation_mode: Video Source`.\n",
        "  video_path = \"\"#@param{type:\"string\"}\n",
        "  frame_stride = 1#@param{type:\"number\"}\n",
        "  reencode_each_frame = True #@param{type:\"boolean\"}\n",
        "  flow_long_term_samples = 1#@param{type:\"number\"}\n",
        "  #@markdown ---\n",
        "  #@markdown ###Image Motion:\n",
        "  translate_x    = \"-1700*sin(radians(1.5))\" #@param{type:\"string\"}\n",
        "  translate_y    = \"0\" #@param{type:\"string\"}\n",
        "  #@markdown `..._3d` is only used in 3D mode.\n",
        "  translate_z_3d = \"(50+10*t)*sin(t/10*pi)**2\" #@param{type:\"string\"}\n",
        "  #@markdown `rotate_3d` *must* be a `[w,x,y,z]` rotation (unit) quaternion. Use `rotate_3d: [1,0,0,0]` for no rotation.\n",
        "  #@markdown [Learn more about rotation quaternions here](https://eater.net/quaternions).\n",
        "  rotate_3d      = \"[cos(radians(1.5)), 0, -sin(radians(1.5))/sqrt(2), sin(radians(1.5))/sqrt(2)]\"#@param{type:\"string\"}\n",
        "  #@markdown `..._2d` is only used in 2D mode.\n",
        "  rotate_2d      = \"5\" #@param{type:\"string\"}\n",
        "  zoom_x_2d      = \"0\" #@param{type:\"string\"}\n",
        "  zoom_y_2d      = \"0\" #@param{type:\"string\"}\n",
        "  #@markdown  3D camera (only used in 3D mode):\n",
        "  lock_camera   = True#@param{type:\"boolean\"}\n",
        "  field_of_view = 60#@param{type:\"number\"}\n",
        "  near_plane    = 1#@param{type:\"number\"}\n",
        "  far_plane     = 10000#@param{type:\"number\"}\n",
        "\n",
        "  #@markdown ---\n",
        "  #@markdown ###Output:\n",
        "  file_namespace = \"default\"#@param{type:\"string\"}\n",
        "  if file_namespace == '':\n",
        "    file_namespace = 'out'\n",
        "  allow_overwrite = False#@param{type:\"boolean\"}\n",
        "  base_name = file_namespace\n",
        "  if not allow_overwrite and path_exists(f'images_out/{file_namespace}'):\n",
        "    _, i = get_last_file(f'images_out/{file_namespace}', \n",
        "                         f'^(?P<pre>{re.escape(file_namespace)}\\\\(?)(?P<index>\\\\d*)(?P<post>\\\\)?_1\\\\.png)$')\n",
        "    if i == 0:\n",
        "      print(f\"WARNING: file_namespace {file_namespace} already has images from run 0\")\n",
        "    elif i is not None:\n",
        "      print(f\"WARNING: file_namespace {file_namespace} already has images from runs 0 through {i}\")\n",
        "  elif glob.glob(f'images_out/{file_namespace}/{base_name}_*.png'):\n",
        "    print(f\"WARNING: file_namespace {file_namespace} has images which will be overwritten\")\n",
        "  try:\n",
        "    del i\n",
        "    del _\n",
        "  except NameError:\n",
        "    pass\n",
        "  del base_name\n",
        "  display_every = steps_per_frame #@param{type:\"raw\"}\n",
        "  clear_every = 0 #@param{type:\"raw\"}\n",
        "  display_scale = 1#@param{type:\"number\"}\n",
        "  save_every = steps_per_frame #@param{type:\"raw\"}\n",
        "  backups =  2**(flow_long_term_samples+1)+1#this is used for video transfer, so don't lower it if that's what you're doing#@param {type:\"raw\"}\n",
        "  show_graphs = False #@param{type:\"boolean\"}\n",
        "  approximate_vram_usage = False#@param{type:\"boolean\"}\n",
        "\n",
        "  #@markdown ---\n",
        "  #@markdown ###Model:\n",
        "  #@markdown Quality settings from Dribnet's CLIPIT (https://github.com/dribnet/clipit).\n",
        "  #@markdown Selecting too many will use up all your VRAM and slow down the model.\n",
        "  #@markdown I usually use ViTB32, ViTB16, and RN50 if I get a A100, otherwise I just use ViT32B.\n",
        "\n",
        "  #@markdown quality | CLIP models\n",
        "  #@markdown --- | --\n",
        "  #@markdown  draft | ViTB32 \n",
        "  #@markdown  normal | ViTB32, ViTB16 \n",
        "  #@markdown  high | ViTB32, ViTB16, RN50\n",
        "  #@markdown  best | ViTB32, ViTB16, RN50x4\n",
        "  ViTB32 = True #@param{type:\"boolean\"}\n",
        "  ViTB16 = False #@param{type:\"boolean\"}\n",
        "  RN50 = False #@param{type:\"boolean\"}\n",
        "  RN50x4 = False #@param{type:\"boolean\"}\n",
        "  #@markdown the default learning rate is `0.1` for all the VQGAN models\n",
        "  #@markdown except openimages, which is `0.15`. For the palette modes the\n",
        "  #@markdown default is `0.02`. \n",
        "  learning_rate =  model_default#@param{type:\"raw\"}\n",
        "  reset_lr_each_frame = True#@param{type:\"boolean\"}\n",
        "  seed = random_seed #@param{type:\"raw\"}\n",
        "  #@markdown **Cutouts**:\n",
        "\n",
        "  #@markdown [Cutouts are how CLIP sees the image.](https://twitter.com/remi_durant/status/1460607677801897990)\n",
        "  cutouts =  40#@param{type:\"number\"}\n",
        "  cut_pow =  2#@param {type:\"number\"}\n",
        "  cutout_border =  .25#@param {type:\"number\"}\n",
        "  #@markdown NOTE: prompt masks (`promt:weight_[mask.png]`) will not work right on '`wrap`' or '`mirror`' mode.\n",
        "  border_mode = \"clamp\" #@param [\"clamp\",\"mirror\",\"wrap\",\"black\",\"smear\"]\n",
        "  \n",
        "  if seed is None:\n",
        "    seed = random.randint(-0x8000_0000_0000_0000, 0xffff_ffff_ffff_ffff)\n",
        "  locals_after = locals().copy()\n",
        "  for k in locals_before.keys():\n",
        "    del locals_after[k]\n",
        "  del locals_after['locals_before']\n",
        "  return locals_after\n",
        "\n",
        "params = Bunch(define_parameters())\n",
        "print(\"SETTINGS:\")\n",
        "print(json.dumps(params))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWlZ2Gocb2fF",
        "cellView": "form"
      },
      "source": [
        "#@title 2.2 Load settings (optional)\n",
        "#@markdown copy the `SETTINGS:` output from the **Parameters** cell (tripple click to select the whole\n",
        "#@markdown line from `{'scenes'...` to `}`) and paste them in a note to save them for later.\n",
        "\n",
        "#@markdown Paste them here in the future to load those settings again. Running this cell with blank settings won't do anything.\n",
        "from os.path import exists as path_exists\n",
        "if path_exists('/content/drive/MyDrive/pytti_test'):\n",
        "  %cd /content/drive/MyDrive/pytti_test\n",
        "  drive_mounted = True\n",
        "else:\n",
        "  drive_mounted = False\n",
        "try:\n",
        "  from pytti.Notebook import *\n",
        "except ModuleNotFoundError:\n",
        "  if drive_mounted:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('ERROR: please run setup (step 1.3).')\n",
        "  else:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('WARNING: drive is not mounted.\\nERROR: please run setup (step 1.3).')\n",
        "change_tqdm_color()\n",
        "  \n",
        "import json, random\n",
        "try:\n",
        "  from bunch import Bunch\n",
        "except ModuleNotFoundError:\n",
        "  if drive_mounted:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('ERROR: please run setup (step 1.3).')\n",
        "  else:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('WARNING: drive is not mounted.\\nERROR: please run setup (step 1.3).')\n",
        "\n",
        "settings = \"\"#@param{type:\"string\"}\n",
        "#@markdown Check `random_seed` to overwrite the seed from the settings with a random one for some variation.\n",
        "random_seed = False #@param{type:\"boolean\"}\n",
        "\n",
        "if settings != '':\n",
        "  params = load_settings(settings, random_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqJ6vY2z3rR8",
        "cellView": "form"
      },
      "source": [
        "#@title 2.3 Run it!\n",
        "#@markdown pytti is 1000% percent better code than VQLIPSE, so have a look at the code. \n",
        "#@markdown You just might understand what's going on.\n",
        "import torch\n",
        "\n",
        "from os.path import exists as path_exists\n",
        "if path_exists('/content/drive/MyDrive/pytti_test'):\n",
        "  %cd /content/drive/MyDrive/pytti_test\n",
        "  drive_mounted = True\n",
        "else:\n",
        "  drive_mounted = False\n",
        "try:\n",
        "  from pytti.Notebook import *\n",
        "except ModuleNotFoundError:\n",
        "  if drive_mounted:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('ERROR: please run setup (step 1.3).')\n",
        "  else:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('WARNING: drive is not mounted.\\nERROR: please run setup (step 1.3).')\n",
        "change_tqdm_color()\n",
        "import sys\n",
        "sys.path.append('./AdaBins')\n",
        "\n",
        "try:\n",
        "  from pytti import Perceptor\n",
        "except ModuleNotFoundError:\n",
        "  if drive_mounted:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('ERROR: please run setup (step 1.3).')\n",
        "  else:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('WARNING: drive is not mounted.\\nERROR: please run setup (step 1.3).')\n",
        "print(\"Loading pytti...\")\n",
        "from pytti.Image import PixelImage, RGBImage, VQGANImage\n",
        "from pytti.ImageGuide import DirectImageGuide\n",
        "from pytti.Perceptor.Embedder import HDMultiClipEmbedder\n",
        "from pytti.Perceptor.Prompt import parse_prompt\n",
        "from pytti.LossAug import TVLoss, HSVLoss, OpticalFlowLoss, TargetFlowLoss\n",
        "from pytti.Transforms import zoom_2d, zoom_3d, apply_flow\n",
        "from pytti import *\n",
        "from pytti.LossAug.DepthLoss import init_AdaBins\n",
        "print(\"pytti loaded.\")\n",
        "\n",
        "import torch, gc, glob, subprocess, warnings, re, math, json\n",
        "import numpy as np\n",
        "from IPython import display\n",
        "from PIL import Image, ImageEnhance\n",
        "\n",
        "from torchvision.transforms import functional as TF\n",
        "\n",
        "#display settings, because usability counts\n",
        "#warnings.filterwarnings(\"error\", category=UserWarning)\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "import pandas as pd\n",
        "plt.style.use('bmh')\n",
        "pd.options.display.max_columns = None\n",
        "pd.options.display.width = 175\n",
        "\n",
        "latest = -1\n",
        "#@markdown check `batch_mode` to run batch settings\n",
        "batch_mode = False #@param{type:\"boolean\"}\n",
        "if batch_mode:\n",
        "  try:\n",
        "    batch_list\n",
        "  except NameError:\n",
        "    raise RuntimeError(\"ERROR: no batch settings. Please run 'batch settings' cell at the bottom of the page to use batch mode.\")\n",
        "else:\n",
        "  try:\n",
        "    params\n",
        "  except NameError:\n",
        "    raise RuntimeError(\"ERROR: no parameters. Please run parameters (step 2.1).\")\n",
        "#@markdown check `restore` to restore from a previous run\n",
        "restore = False#@param{type:\"boolean\"}\n",
        "#@markdown check `reencode` if you are restoring with a modified image or modified image settings\n",
        "reencode = False#@param{type:\"boolean\"}\n",
        "#@markdown which run to restore\n",
        "restore_run = latest #@param{type:\"raw\"}\n",
        "if restore and restore_run == latest:\n",
        "  _, restore_run = get_last_file(f'backup/{params.file_namespace}', \n",
        "                           f'^(?P<pre>{re.escape(params.file_namespace)}\\\\(?)(?P<index>\\\\d*)(?P<post>\\\\)?_\\\\d+\\\\.bak)$')\n",
        "\n",
        "def do_run():\n",
        "  clear_rotoscopers()#what a silly name\n",
        "  vram_profiling(params.approximate_vram_usage)\n",
        "  reset_vram_usage()\n",
        "  global CLIP_MODEL_NAMES\n",
        "  #@markdown which frame to restore from\n",
        "  restore_frame =  latest#@param{type:\"raw\"}\n",
        "\n",
        "  #set up seed for deterministic RNG\n",
        "  if params.seed is not None:\n",
        "    torch.manual_seed(params.seed)\n",
        "\n",
        "  #load CLIP\n",
        "  load_clip(params)\n",
        "  embedder = HDMultiClipEmbedder(cutn=params.cutouts, \n",
        "                                 cut_pow = params.cut_pow, \n",
        "                                 padding = params.cutout_border,\n",
        "                                 border_mode = params.border_mode)\n",
        "  \n",
        "  #load scenes\n",
        "  with vram_usage_mode('Text Prompts'):\n",
        "    print('Loading prompts...')\n",
        "    prompts = [[parse_prompt(embedder, p.strip()) \n",
        "              for p in (params.scene_prefix + stage + params.scene_suffix).strip().split('|') if p.strip()]\n",
        "              for stage in params.scenes.split('||') if stage]\n",
        "    print('Prompts loaded.')\n",
        "\n",
        "  #load init image\n",
        "  if params.init_image != '':\n",
        "    init_image_pil = Image.open(fetch(params.init_image)).convert('RGB')\n",
        "    init_size = init_image_pil.size\n",
        "    #automatic aspect ratio matching\n",
        "    if params.width == -1:\n",
        "      params.width = int(params.height*init_size[0]/init_size[1])\n",
        "    if params.height == -1:\n",
        "      params.height = int(params.width*init_size[1]/init_size[0])\n",
        "  else:\n",
        "    init_image_pil = None\n",
        "\n",
        "  #video source\n",
        "  if params.animation_mode == \"Video Source\":\n",
        "    print(f'loading {params.video_path}...')\n",
        "    video_frames = get_frames(params.video_path)\n",
        "    params.pre_animation_steps = max(params.steps_per_frame, params.pre_animation_steps)\n",
        "    if init_image_pil is None:\n",
        "      init_image_pil = Image.fromarray(video_frames.get_data(0)).convert('RGB')\n",
        "      #enhancer = ImageEnhance.Contrast(init_image_pil)\n",
        "      #init_image_pil = enhancer.enhance(2)\n",
        "      init_size = init_image_pil.size\n",
        "      if params.width == -1:\n",
        "        params.width = int(params.height*init_size[0]/init_size[1])\n",
        "      if params.height == -1:\n",
        "        params.height = int(params.width*init_size[1]/init_size[0])\n",
        "\n",
        "  #set up image\n",
        "  if params.image_model == \"Limited Palette\":\n",
        "    img = PixelImage(*format_params(params,\n",
        "                     'width', 'height', 'pixel_size', \n",
        "                     'palette_size', 'palettes', 'gamma', \n",
        "                     'hdr_weight', 'palette_normalization_weight'))\n",
        "    img.encode_random(random_pallet = params.random_initial_palette)\n",
        "    if params.target_palette.strip() != '':\n",
        "      img.set_pallet_target(Image.open(fetch(params.target_palette)).convert('RGB'))\n",
        "    else:\n",
        "      img.lock_pallet(params.lock_palette)\n",
        "  elif params.image_model == \"Unlimited Palette\":\n",
        "    img = RGBImage(params.width, params.height, params.pixel_size)\n",
        "    img.encode_random()\n",
        "  elif params.image_model == \"VQGAN\":\n",
        "    VQGANImage.init_vqgan(params.vqgan_model)\n",
        "    img = VQGANImage(params.width, params.height, params.pixel_size)\n",
        "    img.encode_random()\n",
        "\n",
        "  loss_augs = []\n",
        "\n",
        "  if init_image_pil is not None:\n",
        "    if not restore:\n",
        "      print(\"Encoding image...\")\n",
        "      img.encode_image(init_image_pil)\n",
        "      print(\"Encoded Image:\")\n",
        "      display.display(img.decode_image())\n",
        "    #set up init image prompt\n",
        "    init_augs = ['direct_init_weight']\n",
        "    init_augs = [build_loss(x,params[x],f'init image ({params.init_image})', img, init_image_pil) \n",
        "                  for x in init_augs if params[x] not in ['','0']]\n",
        "    loss_augs.extend(init_augs)\n",
        "    if params.semantic_init_weight not in ['','0']:\n",
        "      semantic_init_prompt = parse_prompt(embedder, \n",
        "                                    f\"init image [{params.init_image}]:{params.semantic_init_weight}\", \n",
        "                                    init_image_pil)\n",
        "      prompts[0].append(semantic_init_prompt)\n",
        "    else:\n",
        "      semantic_init_prompt = None\n",
        "  else:\n",
        "    init_augs, semantic_init_prompt = [], None\n",
        "\n",
        "  #other image prompts\n",
        "\n",
        "  loss_augs.extend(type(img).get_preferred_loss().TargetImage(p.strip(), img.image_shape, is_path = True) \n",
        "                   for p in params.direct_image_prompts.split('|') if p.strip())\n",
        "\n",
        "  #stabilization\n",
        "\n",
        "  stabilization_augs = ['direct_stabilization_weight',\n",
        "                        'depth_stabilization_weight',\n",
        "                        'edge_stabilization_weight']\n",
        "  stabilization_augs = [build_loss(x,params[x],'stabilization',\n",
        "                                   img, init_image_pil) \n",
        "                        for x in stabilization_augs if params[x] not in ['','0']]\n",
        "  loss_augs.extend(stabilization_augs)\n",
        "  \n",
        "  if params.semantic_stabilization_weight not in ['0','']:\n",
        "    last_frame_semantic = parse_prompt(embedder, \n",
        "                                       f\"stabilization:{params.semantic_stabilization_weight}\", \n",
        "                                       init_image_pil if init_image_pil else img.decode_image())\n",
        "    last_frame_semantic.set_enabled(init_image_pil is not None)\n",
        "    for scene in prompts:\n",
        "      scene.append(last_frame_semantic)\n",
        "  else:\n",
        "    last_frame_semantic = None\n",
        "\n",
        "  #optical flow\n",
        "  if params.animation_mode == 'Video Source':\n",
        "    if params.flow_stabilization_weight == '':\n",
        "      params.flow_stabilization_weight = '0'\n",
        "    optical_flows = [OpticalFlowLoss.TargetImage(f\"optical flow stabilization (frame {-2**i}):{params.flow_stabilization_weight}\", \n",
        "                                                 img.image_shape) \n",
        "                     for i in range(params.flow_long_term_samples + 1)]\n",
        "    for optical_flow in optical_flows:\n",
        "      optical_flow.set_enabled(False)\n",
        "    loss_augs.extend(optical_flows)\n",
        "  elif params.animation_mode == '3D' and params.flow_stabilization_weight not in ['0','']:\n",
        "    optical_flows = [TargetFlowLoss.TargetImage(f\"optical flow stabilization:{params.flow_stabilization_weight}\", \n",
        "                                                img.image_shape)]\n",
        "    for optical_flow in optical_flows:\n",
        "      optical_flow.set_enabled(False)\n",
        "    loss_augs.extend(optical_flows)\n",
        "  else:\n",
        "    optical_flows = []\n",
        "  #other loss augs\n",
        "  if params.smoothing_weight != 0:\n",
        "    loss_augs.append(TVLoss(weight = params.smoothing_weight))\n",
        "  \n",
        "  #set up filespace\n",
        "  subprocess.run(['mkdir','-p',f'images_out/{params.file_namespace}'])\n",
        "  subprocess.run(['mkdir','-p',f'backup/{params.file_namespace}'])\n",
        "  if restore:\n",
        "    base_name = params.file_namespace if restore_run == 0 else f'{params.file_namespace}({restore_run})'\n",
        "  elif not params.allow_overwrite:\n",
        "    #finds the next available base_name to save files with. Why did I do this with regex? \n",
        "    _, i = get_next_file(f'images_out/{params.file_namespace}', \n",
        "                         f'^(?P<pre>{re.escape(params.file_namespace)}\\\\(?)(?P<index>\\\\d*)(?P<post>\\\\)?_1\\\\.png)$',\n",
        "                         [f\"{params.file_namespace}_1.png\",f\"{params.file_namespace}(1)_1.png\"])\n",
        "    base_name = params.file_namespace if i == 0 else f'{params.file_namespace}({i})'\n",
        "  else:\n",
        "    base_name = params.file_namespace\n",
        "\n",
        "  #restore\n",
        "  if restore:\n",
        "    if not reencode:\n",
        "      if restore_frame == latest:\n",
        "        filename, restore_frame = get_last_file(f'backup/{params.file_namespace}', \n",
        "                                                f'^(?P<pre>{re.escape(base_name)}_)(?P<index>\\\\d*)(?P<post>\\\\.bak)$')\n",
        "      else: \n",
        "        filename = f'{base_name}_{restore_frame}.bak'\n",
        "      print(\"restoring from\", filename)\n",
        "      img.load_state_dict(torch.load(f'backup/{params.file_namespace}/{filename}'))\n",
        "    else:#reencode\n",
        "      if restore_frame == latest:\n",
        "        filename, restore_frame = get_last_file(f'images_out/{params.file_namespace}', \n",
        "                                                f'^(?P<pre>{re.escape(base_name)}_)(?P<index>\\\\d*)(?P<post>\\\\.png)$')\n",
        "      else: \n",
        "        filename = f'{base_name}_{restore_frame}.png'\n",
        "      print(\"restoring from\", filename)\n",
        "      img.encode_image(Image.open(f'images_out/{params.file_namespace}/{filename}').convert('RGB'))\n",
        "    i = restore_frame*params.save_every\n",
        "  else:\n",
        "    i = 0\n",
        "\n",
        "  #graphs\n",
        "  if params.show_graphs:\n",
        "    fig, axs = plt.subplots(4, 1, figsize=(21,13))\n",
        "    axs  = np.asarray(axs).flatten()\n",
        "    #fig.facecolor = (0,0,0)\n",
        "  else:\n",
        "    fig, axs = None, None\n",
        "\n",
        "  #make the main model object\n",
        "  model = DirectImageGuide(img, embedder, lr = params.learning_rate)\n",
        "\n",
        "  #Update is called each step.\n",
        "  def update(i, stage_i):\n",
        "    #display\n",
        "    if params.clear_every > 0 and i > 0 and i % params.clear_every == 0:\n",
        "      display.clear_output()\n",
        "    if params.display_every > 0 and i % params.display_every == 0:\n",
        "      print(f\"Step {i} losses:\")\n",
        "      if model.dataframe:\n",
        "        print(model.dataframe[0].iloc[-1])\n",
        "      if params.approximate_vram_usage:\n",
        "        print(\"VRAM Usage:\")\n",
        "        print_vram_usage()\n",
        "      display_width = int(img.image_shape[0]*params.display_scale)\n",
        "      display_height = int(img.image_shape[1]*params.display_scale)\n",
        "      if stage_i > 0 and params.show_graphs:\n",
        "        model.plot_losses(axs)\n",
        "        im = img.decode_image()\n",
        "        sidebyside = make_hbox(im.resize((display_width, display_height), Image.LANCZOS), fig)\n",
        "        display.display(sidebyside)\n",
        "      else:\n",
        "        im = img.decode_image()\n",
        "        display.display(im.resize((display_width, display_height), Image.LANCZOS))\n",
        "      if params.show_palette and isinstance(img, PixelImage):\n",
        "        print('Palette:')\n",
        "        display.display(img.render_pallet())\n",
        "    #save\n",
        "    if i > 0 and params.save_every > 0 and i % params.save_every == 0:\n",
        "      try:\n",
        "        im\n",
        "      except NameError:\n",
        "        im = img.decode_image()\n",
        "      n = i//params.save_every\n",
        "      filename = f\"images_out/{params.file_namespace}/{base_name}_{n}.png\"\n",
        "      im.save(filename)\n",
        "      if params.backups > 0:\n",
        "        filename = f\"backup/{params.file_namespace}/{base_name}_{n}.bak\"\n",
        "        torch.save(img.state_dict(), filename)\n",
        "        if n > params.backups:\n",
        "          subprocess.run(['rm', f\"backup/{params.file_namespace}/{base_name}_{n-params.backups}.bak\"])\n",
        "    #animate\n",
        "    t = (i - params.pre_animation_steps)/(params.steps_per_frame*params.frames_per_second)\n",
        "    set_t(t)\n",
        "    if i >= params.pre_animation_steps:\n",
        "      if (i - params.pre_animation_steps) % params.steps_per_frame == 0:\n",
        "        print(f\"Time: {t:.4f} seconds\")\n",
        "        update_rotoscopers(((i - params.pre_animation_steps)//params.steps_per_frame+1)*params.frame_stride)\n",
        "        if params.reset_lr_each_frame:\n",
        "          model.set_optim(None)\n",
        "        if params.animation_mode == \"2D\":\n",
        "          tx, ty = parametric_eval(params.translate_x), parametric_eval(params.translate_y)\n",
        "          theta = parametric_eval(params.rotate_2d)\n",
        "          zx, zy = parametric_eval(params.zoom_x_2d), parametric_eval(params.zoom_y_2d)\n",
        "          next_step_pil = zoom_2d(img, \n",
        "                                  (tx,ty), (zx,zy), theta, \n",
        "                                  border_mode = params.infill_mode, sampling_mode = params.sampling_mode)\n",
        "        elif params.animation_mode == \"3D\":\n",
        "          try:\n",
        "            im\n",
        "          except NameError:\n",
        "            im = img.decode_image()\n",
        "          with vram_usage_mode('Optical Flow Loss'):\n",
        "            flow, next_step_pil = zoom_3d(img, \n",
        "                                        (params.translate_x,params.translate_y,params.translate_z_3d), params.rotate_3d, \n",
        "                                        params.field_of_view, params.near_plane, params.far_plane,\n",
        "                                        border_mode = params.infill_mode, sampling_mode = params.sampling_mode,\n",
        "                                        stabilize = params.lock_camera)\n",
        "            freeze_vram_usage()\n",
        "            \n",
        "          for optical_flow in optical_flows:\n",
        "            optical_flow.set_last_step(im)\n",
        "            optical_flow.set_target_flow(flow)\n",
        "            optical_flow.set_enabled(True)\n",
        "        elif params.animation_mode == \"Video Source\":\n",
        "          frame_n = min((i - params.pre_animation_steps)*params.frame_stride//params.steps_per_frame, len(video_frames) - 1)\n",
        "          next_frame_n = min(frame_n + params.frame_stride, len(video_frames) - 1)\n",
        "          next_step_pil = Image.fromarray(video_frames.get_data(next_frame_n)).convert('RGB').resize(img.image_shape, Image.LANCZOS)\n",
        "          for j, optical_flow in enumerate(optical_flows):\n",
        "            old_frame_n = frame_n - (2**j - 1)*params.frame_stride\n",
        "            save_n = i//params.save_every - (2**j - 1)\n",
        "            if old_frame_n < 0 or save_n < 1:\n",
        "              break\n",
        "            current_step_pil = Image.fromarray(video_frames.get_data(old_frame_n)).convert('RGB').resize(img.image_shape, Image.LANCZOS)\n",
        "            filename = f\"backup/{params.file_namespace}/{base_name}_{save_n}.bak\"\n",
        "            filename = None if j == 0 else filename\n",
        "            flow_im, mask_tensor = optical_flow.set_flow(current_step_pil, next_step_pil, \n",
        "                                                        img, filename, \n",
        "                                                        params.infill_mode, params.sampling_mode)\n",
        "            optical_flow.set_enabled(True)\n",
        "            #first flow is previous frame\n",
        "            if j == 0:\n",
        "              mask_accum = mask_tensor.detach()\n",
        "              valid = mask_tensor.mean()\n",
        "              print(\"valid pixels:\", valid)\n",
        "              if params.reencode_each_frame or valid < .03:\n",
        "                if isinstance(img, PixelImage) and valid >= .03:\n",
        "                  img.lock_pallet()\n",
        "                  img.encode_image(next_step_pil, smart_encode = False)\n",
        "                  img.lock_pallet(params.lock_palette)\n",
        "                else:\n",
        "                  img.encode_image(next_step_pil)\n",
        "                reencoded = True\n",
        "              else:\n",
        "                reencoded = False\n",
        "            else:\n",
        "              with torch.no_grad():\n",
        "                optical_flow.set_mask((mask_tensor - mask_accum).clamp(0,1))\n",
        "                mask_accum.add_(mask_tensor)\n",
        "        if params.animation_mode != 'off':\n",
        "          for aug in stabilization_augs:\n",
        "            aug.set_comp(next_step_pil)\n",
        "            aug.set_enabled(True)\n",
        "          if last_frame_semantic is not None:\n",
        "            last_frame_semantic.set_image(embedder, next_step_pil)\n",
        "            last_frame_semantic.set_enabled(True)\n",
        "          for aug in init_augs:\n",
        "            aug.set_enabled(False)\n",
        "          if semantic_init_prompt is not None:\n",
        "            semantic_init_prompt.set_enabled(False)\n",
        "            \n",
        "      \n",
        "  model.update = update\n",
        "  \n",
        "  print(f\"Settings saved to images_out/{params.file_namespace}/{base_name}_settings.txt\")\n",
        "  save_settings(params, f\"images_out/{params.file_namespace}/{base_name}_settings.txt\")\n",
        "\n",
        "  skip_prompts = i // params.steps_per_scene\n",
        "  skip_steps   = i %  params.steps_per_scene\n",
        "  last_scene = prompts[0] if skip_prompts == 0 else prompts[skip_prompts - 1]\n",
        "  for scene in prompts[skip_prompts:]:\n",
        "    print(\"Running prompt:\", ' | '.join(map(str,scene)))\n",
        "    i += model.run_steps(params.steps_per_scene-skip_steps, \n",
        "                         scene, last_scene, loss_augs, \n",
        "                         interp_steps = params.interpolation_steps,\n",
        "                         i_offset = i, skipped_steps = skip_steps)\n",
        "    skip_steps = 0\n",
        "    model.clear_dataframe()\n",
        "    last_scene = scene\n",
        "  if fig:\n",
        "    del fig, axs\n",
        "\n",
        "#if __name__ == '__main__':\n",
        "try:\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "  if batch_mode:\n",
        "    if restore:\n",
        "      settings_list = batch_list[restore_run:]\n",
        "    else:\n",
        "      settings_list = batch_list\n",
        "      namespace = batch_list[0]['file_namespace']\n",
        "      subprocess.run(['mkdir','-p',f'images_out/{namespace}'])\n",
        "      save_batch(batch_list, f'images_out/{namespace}/{namespace}_batch settings.txt')\n",
        "      print(f\"Batch settings saved to images_out/{namespace}/{namespace}_batch settings.txt\")\n",
        "    for settings in settings_list:\n",
        "      setting_string = json.dumps(settings)\n",
        "      print(\"SETTINGS:\")\n",
        "      print(setting_string)\n",
        "      params = load_settings(setting_string)\n",
        "      if params.animation_mode == '3D':\n",
        "        init_AdaBins()\n",
        "      params.allow_overwrite = False\n",
        "      do_run()\n",
        "      restore = False\n",
        "      reencode = False\n",
        "      gc.collect()\n",
        "      torch.cuda.empty_cache()\n",
        "  else:\n",
        "    if params.animation_mode == '3D':\n",
        "      pass\n",
        "      #init_AdaBins()\n",
        "    do_run()\n",
        "    print(\"Complete.\")\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "except KeyboardInterrupt:\n",
        "  pass\n",
        "except RuntimeError:\n",
        "  print_vram_usage()\n",
        "  raise\n",
        "      \n",
        "#print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtekvTZxFNpf"
      },
      "source": [
        "# Step 3: Render video\n",
        "You can dowload from the notebook, but it's faster to download from your drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZH-r4yyShnX",
        "cellView": "form"
      },
      "source": [
        "#@title 3.1 Render video\n",
        "from os.path import exists as path_exists\n",
        "if path_exists('/content/drive/MyDrive/pytti_test'):\n",
        "  %cd /content/drive/MyDrive/pytti_test\n",
        "  drive_mounted = True\n",
        "else:\n",
        "  drive_mounted = False\n",
        "try:\n",
        "  from pytti.Notebook import change_tqdm_color\n",
        "except ModuleNotFoundError:\n",
        "  if drive_mounted:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('ERROR: please run setup (step 1.3).')\n",
        "  else:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('WARNING: drive is not mounted.\\nERROR: please run setup (step 1.3).')\n",
        "change_tqdm_color()\n",
        "  \n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "from os.path import exists as path_exists\n",
        "from subprocess import Popen, PIPE\n",
        "from PIL import Image, ImageFile\n",
        "from os.path import splitext as split_file\n",
        "import glob\n",
        "from pytti.Notebook import get_last_file\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "try:\n",
        "  params\n",
        "except NameError:\n",
        "  raise RuntimeError(\"ERROR: no parameters. Please run parameters (step 2.1).\")\n",
        "\n",
        "if not path_exists(f\"images_out/{params.file_namespace}\"):\n",
        "  if path_exists(f\"/content/drive/MyDrive\"):\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError(f\"ERROR: file_namespace: {params.file_namespace} does not exist.\")\n",
        "  else:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError(f\"WARNING: Drive is not mounted.\\nERROR: file_namespace: {params.file_namespace} does not exist.\")\n",
        "\n",
        "#@markdown The first run executed in `file_namespace` is number $0$, the second is number $1$, etc.\n",
        "\n",
        "latest = -1\n",
        "run_number = latest#@param{type:\"raw\"}\n",
        "if run_number == -1:\n",
        "  _, i = get_last_file(f'images_out/{params.file_namespace}', \n",
        "                       f'^(?P<pre>{re.escape(params.file_namespace)}\\\\(?)(?P<index>\\\\d*)(?P<post>\\\\)?_1\\\\.png)$')\n",
        "  run_number = i\n",
        "base_name = params.file_namespace if run_number == 0 else (params.file_namespace+f\"({run_number})\")\n",
        "tqdm.write(f'Generating video from {params.file_namespace}/{base_name}_*.png')\n",
        "\n",
        "all_frames = glob.glob(f'images_out/{params.file_namespace}/{base_name}_*.png')\n",
        "all_frames.sort(key = lambda s: int(split_file(s)[0].split('_')[-1]))\n",
        "print(f'found {len(all_frames)} frames matching images_out/{params.file_namespace}/{base_name}_*.png')\n",
        "\n",
        "start_frame = 0#@param{type:\"number\"}\n",
        "all_frames = all_frames[start_frame:]\n",
        "\n",
        "fps =  params.frames_per_second#@param{type:\"raw\"}\n",
        "\n",
        "total_frames = len(all_frames)\n",
        "\n",
        "if total_frames == 0:\n",
        "  #THIS IS NOT AN ERROR. This is the code that would\n",
        "  #make an error if something were wrong.\n",
        "  raise RuntimeError(f\"ERROR: no frames to render in images_out/{params.file_namespace}\")\n",
        "\n",
        "frames = []\n",
        "\n",
        "for filename in tqdm(all_frames):\n",
        "  frames.append(Image.open(filename))\n",
        "\n",
        "p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '1', '-preset', 'veryslow', f\"videos/{base_name}.mp4\"], stdin=PIPE)\n",
        "for im in tqdm(frames):\n",
        "  im.save(p.stdin, 'PNG')\n",
        "p.stdin.close()\n",
        "\n",
        "print(\"Encoding video...\")\n",
        "p.wait()\n",
        "print(\"Video complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3EgqHKrSjZx",
        "cellView": "form"
      },
      "source": [
        "#@title 3.1 Render video (concatenate all runs)\n",
        "from os.path import exists as path_exists\n",
        "if path_exists('/content/drive/MyDrive/pytti_test'):\n",
        "  %cd /content/drive/MyDrive/pytti_test\n",
        "  drive_mounted = True\n",
        "else:\n",
        "  drive_mounted = False\n",
        "try:\n",
        "  from pytti.Notebook import change_tqdm_color\n",
        "except ModuleNotFoundError:\n",
        "  if drive_mounted:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('ERROR: please run setup (step 1.3).')\n",
        "  else:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('WARNING: drive is not mounted.\\nERROR: please run setup (step 1.3).')\n",
        "change_tqdm_color()\n",
        "  \n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "from os.path import exists as path_exists\n",
        "from subprocess import Popen, PIPE\n",
        "from PIL import Image, ImageFile\n",
        "from os.path import splitext as split_file\n",
        "import glob\n",
        "from pytti.Notebook import get_last_file\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "try:\n",
        "  params\n",
        "except NameError:\n",
        "  raise RuntimeError(\"ERROR: no parameters. Please run parameters (step 2.1).\")\n",
        "\n",
        "if not path_exists(f\"images_out/{params.file_namespace}\"):\n",
        "  if path_exists(f\"/content/drive/MyDrive\"):\n",
        "    raise RuntimeError(f\"ERROR: file_namespace: {params.file_namespace} does not exist.\")\n",
        "  else:\n",
        "    raise RuntimeError(f\"WARNING: Drive is not mounted.\\nERROR: file_namespace: {params.file_namespace} does not exist.\")\n",
        "\n",
        "#@markdown The first run executed in `file_namespace` is number $0$, the second is number $1$, etc.\n",
        "\n",
        "latest = -1\n",
        "run_number = latest\n",
        "if run_number == -1:\n",
        "  _, i = get_last_file(f'images_out/{params.file_namespace}', \n",
        "                       f'^(?P<pre>{re.escape(params.file_namespace)}\\\\(?)(?P<index>\\\\d*)(?P<post>\\\\)?_1\\\\.png)$')\n",
        "  run_number = i\n",
        "\n",
        "all_frames = []\n",
        "for i in range(run_number+1):\n",
        "  base_name = params.file_namespace if i == 0 else (params.file_namespace+f\"({i})\")\n",
        "  frames = glob.glob(f'images_out/{params.file_namespace}/{base_name}_*.png')\n",
        "  frames.sort(key = lambda s: int(split_file(s)[0].split('_')[-1]))\n",
        "  all_frames.extend(frames)\n",
        "\n",
        "start_frame = 0#@param{type:\"number\"}\n",
        "all_frames = all_frames[start_frame:]\n",
        "\n",
        "fps =  params.frames_per_second#@param{type:\"raw\"}\n",
        "\n",
        "total_frames = len(all_frames)\n",
        "\n",
        "if total_frames == 0:\n",
        "  #THIS IS NOT AN ERROR. This is the code that would\n",
        "  #make an error if something were wrong.\n",
        "  raise RuntimeError(f\"ERROR: no frames to render in images_out/{params.file_namespace}\")\n",
        "\n",
        "frames = []\n",
        "\n",
        "for filename in tqdm(all_frames):\n",
        "  frames.append(Image.open(filename))\n",
        "\n",
        "p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '1', '-preset', 'veryslow', f\"videos/{base_name}.mp4\"], stdin=PIPE)\n",
        "for im in tqdm(frames):\n",
        "  im.save(p.stdin, 'PNG')\n",
        "p.stdin.close()\n",
        "\n",
        "print(\"Encoding video...\")\n",
        "p.wait()\n",
        "print(\"Video complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qZ8c_-iZ0QM",
        "cellView": "form"
      },
      "source": [
        "#@title 3.2 Download the last exported video\n",
        "from os.path import exists as path_exists\n",
        "if path_exists('/content/drive/MyDrive/pytti_test'):\n",
        "  %cd /content/drive/MyDrive/pytti_test\n",
        "\n",
        "try:\n",
        "  from pytti.Notebook import get_last_file\n",
        "except ModuleNotFoundError:\n",
        "  if drive_mounted:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('ERROR: please run setup (step 1.3).')\n",
        "  else:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('WARNING: drive is not mounted.\\nERROR: please run setup (step 1.3).')\n",
        "\n",
        "try:\n",
        "  params\n",
        "except NameError:\n",
        "  #THIS IS NOT AN ERROR. This is the code that would\n",
        "  #make an error if something were wrong.\n",
        "  raise RuntimeError(\"ERROR: please run parameters (step 2.1).\")\n",
        "\n",
        "from google.colab import files\n",
        "try:\n",
        "  base_name = params.file_namespace if run_number == 0 else (params.file_namespace+f\"({run_number})\")\n",
        "  filename = f'{base_name}.mp4'\n",
        "except NameError:\n",
        "  filename, i = get_last_file(f'videos', \n",
        "                       f'^(?P<pre>{re.escape(params.file_namespace)}\\\\(?)(?P<index>\\\\d*)(?P<post>\\\\)?\\\\.mp4)$')\n",
        "\n",
        "if path_exists(f'videos/{filename}'):\n",
        "  files.download(f\"videos/{filename}\")\n",
        "else:\n",
        "  if path_exists(f\"/content/drive/MyDrive\"):\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError(f\"ERROR: video videos/{filename} does not exist.\")\n",
        "  else:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError(f\"WARNING: Drive is not mounted.\\nERROR: video videos/{filename} does not exist.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if_Fdy_OFkjZ"
      },
      "source": [
        "# Batch Setings\n",
        "WARNING: If you use google colab (even with pro and pro+) GPUs for long enought google will throttle your account. Be careful with batch runs if you don't want to get kicked."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHHfWWqoSz35",
        "cellView": "form"
      },
      "source": [
        "#@title batch settings\n",
        "from os.path import exists as path_exists\n",
        "if path_exists('/content/drive/MyDrive/pytti_test'):\n",
        "  %cd /content/drive/MyDrive/pytti_test\n",
        "  drive_mounted = True\n",
        "else:\n",
        "  drive_mounted = False\n",
        "try:\n",
        "  from pytti.Notebook import change_tqdm_color, save_batch\n",
        "except ModuleNotFoundError:\n",
        "  if drive_mounted:\n",
        "    raise RuntimeError('ERROR: please run setup (step 1).')\n",
        "  else:\n",
        "    raise RuntimeError('WARNING: drive is not mounted.\\nERROR: please run setup (step 1).')\n",
        "change_tqdm_color()\n",
        "\n",
        "try:\n",
        "  import exrex, random, glob\n",
        "except ModuleNotFoundError:\n",
        "  if drive_mounted:\n",
        "    raise RuntimeError('ERROR: please run setup (step 1).')\n",
        "  else:\n",
        "    raise RuntimeError('WARNING: drive is not mounted.\\nERROR: please run setup (step 1).')\n",
        "from numpy import arange\n",
        "import itertools\n",
        "\n",
        "def all_matches(s):\n",
        "  return list(exrex.generate(s))\n",
        "\n",
        "def dict_product(dictionary):\n",
        "  return [dict(zip(dictionary, x)) for x in itertools.product(*dictionary.values())]\n",
        "\n",
        "#these are used to make the defaults look pretty\n",
        "model_default = None\n",
        "random_seed = None\n",
        "\n",
        "def define_parameters():\n",
        "  locals_before = locals().copy()\n",
        "  scenes = [\"list\",\"your\",\"runs\"] #@param{type:\"raw\"}\n",
        "  scene_prefix = [\"all \",\" permutations \",\" are run \"] #@param{type:\"raw\"}\n",
        "  scene_suffix = [\" that\", \" makes\", \" 27\" ] #@param{type:\"raw\"}\n",
        "  interpolation_steps = [0] #@param{type:\"raw\"}\n",
        "  steps_per_scene = [300] #@param{type:\"raw\"}\n",
        "  direct_image_prompts = [\"\"] #@param{type:\"raw\"}\n",
        "  init_image = [\"\"] #@param{type:\"raw\"}\n",
        "  direct_init_weight = [\"\"] #@param{type:\"raw\"}\n",
        "  semantic_init_weight = [\"\"] #@param{type:\"raw\"}\n",
        "  image_model = [\"Limited Palette\"] #@param{type:\"raw\"}\n",
        "  width = [180] #@param{type:\"raw\"}\n",
        "  height = [112] #@param{type:\"raw\"}\n",
        "  pixel_size = [4] #@param{type:\"raw\"}\n",
        "  smoothing_weight = [0.05] #@param{type:\"raw\"}\n",
        "  vqgan_model = [\"sflckr\"] #@param{type:\"raw\"}\n",
        "  random_initial_palette = [False] #@param{type:\"raw\"}\n",
        "  palette_size = [9] #@param{type:\"raw\"}\n",
        "  palettes = [8] #@param{type:\"raw\"}\n",
        "  gamma = [1] #@param{type:\"raw\"}\n",
        "  hdr_weight = [1.0] #@param{type:\"raw\"}\n",
        "  palette_normalization_weight = [1.0] #@param{type:\"raw\"}\n",
        "  show_palette = [False] #@param{type:\"raw\"}\n",
        "  target_palette = [\"\"] #@param{type:\"raw\"}\n",
        "  lock_palette = [False] #@param{type:\"raw\"}\n",
        "  animation_mode = [\"off\"] #@param{type:\"raw\"}\n",
        "  sampling_mode = [\"bicubic\"] #@param{type:\"raw\"}\n",
        "  infill_mode = [\"wrap\"] #@param{type:\"raw\"}\n",
        "  pre_animation_steps = [100] #@param{type:\"raw\"}\n",
        "  steps_per_frame = [50] #@param{type:\"raw\"}\n",
        "  frames_per_second = [12] #@param{type:\"raw\"}\n",
        "  direct_stabilization_weight = [\"\"] #@param{type:\"raw\"}\n",
        "  semantic_stabilization_weight = [\"\"] #@param{type:\"raw\"}\n",
        "  depth_stabilization_weight = [\"\"] #@param{type:\"raw\"}\n",
        "  edge_stabilization_weight = [\"\"] #@param{type:\"raw\"}\n",
        "  flow_stabilization_weight = [\"\"] #@param{type:\"raw\"}\n",
        "  video_path = [\"\"] #@param{type:\"raw\"}\n",
        "  frame_stride = [1] #@param{type:\"raw\"}\n",
        "  reencode_each_frame = [True] #@param{type:\"raw\"}\n",
        "  flow_long_term_samples = [0] #@param{type:\"raw\"}\n",
        "  translate_x = [\"0\"] #@param{type:\"raw\"}\n",
        "  translate_y = [\"0\"] #@param{type:\"raw\"}\n",
        "  translate_z_3d = [\"0\"] #@param{type:\"raw\"}\n",
        "  rotate_3d = [\"[1,0,0,0]\"] #@param{type:\"raw\"}\n",
        "  rotate_2d = [\"0\"] #@param{type:\"raw\"}\n",
        "  zoom_x_2d = [\"0\"] #@param{type:\"raw\"}\n",
        "  zoom_y_2d = [\"0\"] #@param{type:\"raw\"}\n",
        "  lock_camera = [True] #@param{type:\"raw\"}\n",
        "  field_of_view = [60] #@param{type:\"raw\"}\n",
        "  near_plane = [1] #@param{type:\"raw\"}\n",
        "  far_plane = [10000] #@param{type:\"raw\"}\n",
        "  file_namespace = [\"Basic Batch\"] #@param{type:\"raw\"}\n",
        "  allow_overwrite = [False]\n",
        "  display_every = [50] #@param{type:\"raw\"}\n",
        "  clear_every = [0] #@param{type:\"raw\"}\n",
        "  display_scale = [1] #@param{type:\"raw\"}\n",
        "  save_every = [50] #@param{type:\"raw\"}\n",
        "  backups = [2] #@param{type:\"raw\"}\n",
        "  show_graphs = [False] #@param{type:\"raw\"}\n",
        "  approximate_vram_usage = [False] #@param{type:\"raw\"}\n",
        "  ViTB32 = [True] #@param{type:\"raw\"}\n",
        "  ViTB16 = [False] #@param{type:\"raw\"}\n",
        "  RN50 = [False] #@param{type:\"raw\"}\n",
        "  RN50x4 = [False] #@param{type:\"raw\"}\n",
        "  learning_rate = [None] #@param{type:\"raw\"}\n",
        "  reset_lr_each_frame = [True] #@param{type:\"raw\"}\n",
        "  seed = [None] #@param{type:\"raw\"}\n",
        "  cutouts = [40] #@param{type:\"raw\"}\n",
        "  cut_pow = [2] #@param{type:\"raw\"}\n",
        "  cutout_border = [0.25] #@param{type:\"raw\"}\n",
        "  border_mode = [\"clamp\"] #@param{type:\"raw\"}\n",
        "  locals_after = locals().copy()\n",
        "  for k in locals_before.keys():\n",
        "    del locals_after[k]\n",
        "  del locals_after['locals_before']\n",
        "  return locals_after\n",
        "\n",
        "param_dict = define_parameters()\n",
        "batch_list = dict_product(param_dict)\n",
        "namespace = batch_list[0]['file_namespace']\n",
        "if glob.glob(f'images_out/{namespace}/*.png'):\n",
        "  print(f\"WARNING: images_out/{namespace} contains images. Batch indicies may not match filenames unless restoring.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}